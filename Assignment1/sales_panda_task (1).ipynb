{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "183aa85c-e41a-4b60-b255-cd1fe19b1c90",
   "metadata": {},
   "source": [
    "Task 1:Create a pandas DataFrame from the CSV and from Python lists/dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0c92fd-b9d8-4cfe-9244-be1025db3c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 10\n",
      "New rows added: 1000\n",
      "Final dataset rows: 1010\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_sales = pd.read_csv(r\"D:\\python files\\pandas\\sample.csv\")\n",
    "\n",
    "\n",
    "# 2. Extract unique values \n",
    "\n",
    "store_ids = df_sales[\"store_id\"].unique().tolist()\n",
    "store_names = df_sales[\"store_name\"].unique().tolist()\n",
    "product_ids = df_sales[\"product_id\"].unique().tolist()\n",
    "product_names = df_sales[\"product_name\"].unique().tolist()\n",
    "\n",
    "promo_codes = df_sales[\"promo_code\"].fillna(\"NONE\").unique().tolist()\n",
    "\n",
    "\n",
    "# 3. Generate 1000 new synthetic rows\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "start_txn = df_sales[\"transaction_id\"].max() + 1\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    # Pick random store\n",
    "    sid = random.choice(store_ids)\n",
    "    \n",
    "    # Pick random product\n",
    "    pname = random.choice(product_names)\n",
    "    pid = df_sales[df_sales[\"product_name\"] == pname][\"product_id\"].iloc[0]\n",
    "    \n",
    "    qty = random.randint(1, 10)\n",
    "    price = round(random.uniform(0.50, 15.00), 2)\n",
    "    \n",
    "    # Create a new random row following your schema\n",
    "    row = {\n",
    "        \"transaction_id\": start_txn + i,\n",
    "        \"store_id\": sid,\n",
    "        \"store_name\": random.choice(store_names),\n",
    "        \"date\": f\"2025-10-{random.randint(1, 28):02d}\",\n",
    "        \"product_id\": pid,\n",
    "        \"product_name\": pname,\n",
    "        \"quantity\": qty,\n",
    "        \"unit_price\": price,\n",
    "        \"total\": round(qty * price, 2),\n",
    "        \"customer_id\": random.randint(2001, 5000),\n",
    "        \"promo_code\": random.choice(promo_codes)\n",
    "    }\n",
    "    \n",
    "    new_rows.append(row)\n",
    "\n",
    "\n",
    "df_random = pd.DataFrame(new_rows)\n",
    "\n",
    "\n",
    "# 5. Combine old + new rows\n",
    "\n",
    "df_final = pd.concat([df_sales, df_random], ignore_index=True)\n",
    "\n",
    "\n",
    "# 6. Save expanded dataset\n",
    "\n",
    "df_final.to_csv(r\"D:\\python files\\pandas\\sample_expanded.csv\", index=False)\n",
    "\n",
    "print(\"Original rows:\", len(df_sales))\n",
    "print(\"New rows added: 1000\")\n",
    "print(\"Final dataset rows:\", len(df_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486149e0-637a-4e0e-a711-033d42ce7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales=df_final\n",
    "df_sales[\"date\"] = pd.to_datetime(df_sales[\"date\"], errors=\"coerce\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e415509-a16e-486b-b8d9-d8aecf8b9929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    transaction_id  store_id store_name       date  product_id product_name  \\\n",
      "0             1001         1   Downtown 2025-10-01         501     Notebook   \n",
      "1             1002         1   Downtown 2025-10-01         502          Pen   \n",
      "4             1005         1   Downtown 2025-10-03         504       Folder   \n",
      "7             1008         1   Downtown 2025-10-04         502          Pen   \n",
      "12            1013         1   Downtown 2025-10-20         501     Notebook   \n",
      "\n",
      "    quantity  unit_price  total  customer_id promo_code  \n",
      "0          2        3.50   7.00       2001.0        NaN  \n",
      "1          5        0.80   4.00       2002.0     DISC10  \n",
      "4          3        1.20   3.60       2004.0     DISC10  \n",
      "7          2        0.80   1.60       2002.0        NaN  \n",
      "12         7        1.71  11.97       4989.0      DISC5  \n"
     ]
    }
   ],
   "source": [
    "sales_hyd = df_sales[df_sales[\"store_name\"] == \"Downtown\"]\n",
    "print(sales_hyd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de675e2-7126-472c-be58-d03f178bfc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      transaction_id  store_id store_name       date  product_id product_name  \\\n",
      "0               1001         1   Downtown 2025-10-01         501     Notebook   \n",
      "1               1002         1   Downtown 2025-10-01         502          Pen   \n",
      "4               1005         1   Downtown 2025-10-03         504       Folder   \n",
      "7               1008         1   Downtown 2025-10-04         502          Pen   \n",
      "12              1013         1   Downtown 2025-10-20         501     Notebook   \n",
      "...              ...       ...        ...        ...         ...          ...   \n",
      "988             1989         1   Downtown 2025-10-19         501     Notebook   \n",
      "995             1996         1   Downtown 2025-10-18         506  Highlighter   \n",
      "1001            2002         1     Suburb 2025-10-23         501     Notebook   \n",
      "1002            2003         1   Downtown 2025-10-24         505       Marker   \n",
      "1008            2009         1     Suburb 2025-10-16         503      Stapler   \n",
      "\n",
      "      quantity  unit_price  total  customer_id promo_code  \n",
      "0            2        3.50   7.00       2001.0        NaN  \n",
      "1            5        0.80   4.00       2002.0     DISC10  \n",
      "4            3        1.20   3.60       2004.0     DISC10  \n",
      "7            2        0.80   1.60       2002.0        NaN  \n",
      "12           7        1.71  11.97       4989.0      DISC5  \n",
      "...        ...         ...    ...          ...        ...  \n",
      "988         10        5.47  54.70       2412.0       NONE  \n",
      "995          2       14.15  28.30       3738.0      DISC5  \n",
      "1001         5        8.33  41.65       3870.0     DISC10  \n",
      "1002         3       10.24  30.72       2749.0      DISC5  \n",
      "1008         2       11.89  23.78       2765.0     DISC10  \n",
      "\n",
      "[331 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "sales_store_1001 = df_sales[df_sales[\"store_id\"] == 1]\n",
    "print(sales_store_1001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c32c23-dd5e-416d-8b30-f68882922055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   transaction_id  store_id store_name       date  product_id product_name  \\\n",
      "2            1003         2     Suburb 2025-10-02         501     Notebook   \n",
      "3            1004         2     Suburb 2025-10-02         503      Stapler   \n",
      "4            1005         1   Downtown 2025-10-03         504       Folder   \n",
      "5            1006         3    Airport 2025-10-03         502          Pen   \n",
      "6            1007         3    Airport 2025-10-04         505       Marker   \n",
      "\n",
      "   quantity  unit_price  total  customer_id promo_code  \n",
      "2         1        3.50   3.50       2003.0        NaN  \n",
      "3         1        5.25   5.25          NaN        NaN  \n",
      "4         3        1.20   3.60       2004.0     DISC10  \n",
      "5        10        0.80   8.00       2005.0        NaN  \n",
      "6         2        1.75   3.50       2006.0        NaN  \n"
     ]
    }
   ],
   "source": [
    "sales_date_range = df_sales[\n",
    "    (df_sales[\"date\"] >= \"2025-10-02\") &\n",
    "    (df_sales[\"date\"] <= \"2025-10-05\")\n",
    "]\n",
    "\n",
    "print(sales_date_range.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e63431a7-bd06-41fa-a69a-16b9aa280b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      transaction_id  store_id store_name       date  product_id product_name  \\\n",
      "0               1001         1   Downtown 2025-10-01         501     Notebook   \n",
      "3               1004         2     Suburb 2025-10-02         503      Stapler   \n",
      "5               1006         3    Airport 2025-10-03         502          Pen   \n",
      "10              1011         2     Suburb 2025-10-19         503      Stapler   \n",
      "11              1012         2    Airport 2025-10-12         504       Folder   \n",
      "...              ...       ...        ...        ...         ...          ...   \n",
      "1005            2006         3   Downtown 2025-10-23         503      Stapler   \n",
      "1006            2007         2    Airport 2025-10-23         505       Marker   \n",
      "1007            2008         2    Airport 2025-10-01         501     Notebook   \n",
      "1008            2009         1     Suburb 2025-10-16         503      Stapler   \n",
      "1009            2010         2    Airport 2025-10-11         504       Folder   \n",
      "\n",
      "      quantity  unit_price  total  customer_id promo_code  \n",
      "0            2        3.50   7.00       2001.0        NaN  \n",
      "3            1        5.25   5.25          NaN        NaN  \n",
      "5           10        0.80   8.00       2005.0        NaN  \n",
      "10           1       11.94  11.94       2151.0       NONE  \n",
      "11           6        4.81  28.86       3161.0      DISC5  \n",
      "...        ...         ...    ...          ...        ...  \n",
      "1005         5        9.47  47.35       2887.0     DISC10  \n",
      "1006         4        2.56  10.24       4397.0       NONE  \n",
      "1007        10        8.87  88.70       3859.0       NONE  \n",
      "1008         2       11.89  23.78       2765.0     DISC10  \n",
      "1009        10        9.54  95.40       2807.0       NONE  \n",
      "\n",
      "[938 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "high_value_sales = df_sales[df_sales[\"total\"] > 5.00]\n",
    "print(high_value_sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9532524c-047c-4499-a715-ec3d229df449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       transaction_id     store_id                           date  \\\n",
      "count     1010.000000  1010.000000                           1010   \n",
      "mean      1505.500000     2.000000  2025-10-14 14:15:26.732673024   \n",
      "min       1001.000000     1.000000            2025-10-01 00:00:00   \n",
      "25%       1253.250000     1.000000            2025-10-08 00:00:00   \n",
      "50%       1505.500000     2.000000            2025-10-15 00:00:00   \n",
      "75%       1757.750000     3.000000            2025-10-21 00:00:00   \n",
      "max       2010.000000     3.000000            2025-10-28 00:00:00   \n",
      "std        291.706188     0.809997                            NaN   \n",
      "\n",
      "        product_id     quantity   unit_price        total  customer_id  \n",
      "count  1010.000000  1010.000000  1010.000000  1010.000000  1009.000000  \n",
      "mean    503.388119     5.533663     7.494426    41.618673  3562.295342  \n",
      "min     501.000000     1.000000     0.530000     0.530000  2001.000000  \n",
      "25%     502.000000     3.000000     3.742500    13.435000  2805.000000  \n",
      "50%     503.000000     5.000000     7.265000    29.910000  3615.000000  \n",
      "75%     505.000000     8.000000    11.207500    61.125000  4323.000000  \n",
      "max     506.000000    10.000000    15.000000   149.700000  4989.000000  \n",
      "std       1.682375     2.928510     4.244288    34.860416   875.910492  \n"
     ]
    }
   ],
   "source": [
    "stats_summary = df_sales.describe()\n",
    "print(stats_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af6d6863-4c8c-474a-8a7e-c55689d4c9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  store_name     total\n",
      "0    Airport  14752.36\n",
      "1   Downtown  14327.69\n",
      "2     Suburb  12954.81\n"
     ]
    }
   ],
   "source": [
    "#Total Sales Amount by Store (Store-wise Revenue)\n",
    "store_totals = df_sales.groupby(\"store_name\")[\"total\"].sum().reset_index()\n",
    "print(store_totals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4184b046-5caa-40b8-a068-8dd041e58a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average basket value: 41.618673267326734\n"
     ]
    }
   ],
   "source": [
    "#Average Basket Value (average spend per transaction)\n",
    "\n",
    "#Basket value = total amount spent in one transaction\n",
    "\n",
    "avg_basket = df_sales[\"total\"].mean()\n",
    "print(\"Average basket value:\", avg_basket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3070da1-15c9-4e08-9955-ce2490d3e7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  store_name      total\n",
      "0    Airport  43.389294\n",
      "1   Downtown  42.641935\n",
      "2     Suburb  38.786856\n"
     ]
    }
   ],
   "source": [
    "#Average Basket Value by Store\n",
    "avg_basket_store = df_sales.groupby(\"store_name\")[\"total\"].mean().reset_index()\n",
    "print(avg_basket_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca42e0c-4cca-48e6-a1dc-e3d249573275",
   "metadata": {},
   "source": [
    "Task4: Perform simple cleaning (handle missing values, fix data types, drop duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2323ec3-eab0-4da4-bd7f-034c633db28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date to datetime\n",
    "df_sales[\"date\"] = pd.to_datetime(df_sales[\"date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "193ad738-3127-4662-affa-1b6bc6b726dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert numeric fields correctly\n",
    "df_sales[\"quantity\"] = pd.to_numeric(df_sales[\"quantity\"], errors=\"coerce\")\n",
    "df_sales[\"unit_price\"] = pd.to_numeric(df_sales[\"unit_price\"], errors=\"coerce\")\n",
    "df_sales[\"total\"] = pd.to_numeric(df_sales[\"total\"], errors=\"coerce\")\n",
    "df_sales[\"customer_id\"] = pd.to_numeric(df_sales[\"customer_id\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "405e2b2f-ae1c-48b4-a86f-240fd1dba091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing quantity → assume minimum purchase = 1\n",
    "df_sales[\"quantity\"] = df_sales[\"quantity\"].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee77b87-a94a-4edc-97cc-54f3517b1246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing unit_price → replace with median\n",
    "df_sales[\"unit_price\"] = df_sales[\"unit_price\"].fillna(df_sales[\"unit_price\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab200039-fad5-48e0-aabc-0be2dc716c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing totals → recompute using quantity × unit_price\n",
    "df_sales[\"total\"] = df_sales[\"quantity\"] * df_sales[\"unit_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e097fcb3-4323-41d4-bd8e-ed4f41cb4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing promo_code → replace with “NONE”\n",
    "df_sales[\"promo_code\"] = df_sales[\"promo_code\"].fillna(\"NONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4978a2e-3540-4942-b106-ab319064665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing product_name / store_name → replace with “Unknown”\n",
    "df_sales[\"product_name\"] = df_sales[\"product_name\"].fillna(\"Unknown Product\")\n",
    "df_sales[\"store_name\"] = df_sales[\"store_name\"].fillna(\"Unknown Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "992a18f6-b9e1-4e4d-93f8-d50bddb4bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates based on transaction_id:\n",
    "df_sales.drop_duplicates(subset=[\"transaction_id\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83f37847-90d2-45bb-9f19-5dd7d5d06ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset Index After Cleaning\n",
    "df_sales.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16f38d81-c008-4b21-b632-d96f00bc002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset shape: (1010, 11)\n",
      "   transaction_id  store_id store_name       date  product_id product_name  \\\n",
      "0            1001         1   Downtown 2025-10-01         501     Notebook   \n",
      "1            1002         1   Downtown 2025-10-01         502          Pen   \n",
      "2            1003         2     Suburb 2025-10-02         501     Notebook   \n",
      "3            1004         2     Suburb 2025-10-02         503      Stapler   \n",
      "4            1005         1   Downtown 2025-10-03         504       Folder   \n",
      "\n",
      "   quantity  unit_price  total  customer_id promo_code  \n",
      "0         2        3.50   7.00       2001.0       NONE  \n",
      "1         5        0.80   4.00       2002.0     DISC10  \n",
      "2         1        3.50   3.50       2003.0       NONE  \n",
      "3         1        5.25   5.25          NaN       NONE  \n",
      "4         3        1.20   3.60       2004.0     DISC10  \n"
     ]
    }
   ],
   "source": [
    "#Print Summary After Cleaning\n",
    "print(\"Cleaned dataset shape:\", df_sales.shape)\n",
    "print(df_sales.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867ab598-8c19-4aa4-b7c7-a31dcb9b1321",
   "metadata": {},
   "source": [
    "Task 5:Build a mini ETL pipeline: read CSV → clean & transform → output JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fd68ddf-dfeb-41a4-8bf4-7c93faa92c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2dbfca2-4360-47a5-9aa6-d00f5ab1be9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Fix data types\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "    numeric_cols = [\"quantity\", \"unit_price\", \"total\", \"customer_id\"]\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Handle missing values\n",
    "    df[\"quantity\"] = df[\"quantity\"].fillna(1)\n",
    "    df[\"unit_price\"] = df[\"unit_price\"].fillna(df[\"unit_price\"].median())\n",
    "    df[\"promo_code\"] = df[\"promo_code\"].fillna(\"NONE\")\n",
    "    df[\"product_name\"] = df[\"product_name\"].fillna(\"Unknown Product\")\n",
    "    df[\"store_name\"] = df[\"store_name\"].fillna(\"Unknown Store\")\n",
    "\n",
    "    # Recompute totals\n",
    "    df[\"computed_total\"] = df[\"quantity\"] * df[\"unit_price\"]\n",
    "\n",
    "    # High-value tag\n",
    "    df[\"is_high_value\"] = df[\"computed_total\"] > 1000\n",
    "\n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(subset=[\"transaction_id\"], inplace=True)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c90483d1-4a6d-47c7-86d5-3c2f267600ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(df, output_path=\"clean_sales.json\"):\n",
    "    df.to_json(output_path, orient=\"records\", indent=4, date_format=\"iso\")\n",
    "    print(f\"JSON file created: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "196dce4d-5dd0-4096-a58b-c11cb474c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created: D:\\python files\\pandas\\clean_sales_extended.json\n"
     ]
    }
   ],
   "source": [
    "def run_etl():\n",
    "    # Step 1: Extract\n",
    "    df = extract(\"D:\\python files\\pandas\\sample_expanded.csv\")\n",
    "\n",
    "    # Step 2: Transform\n",
    "    clean_df = transform(df)\n",
    "\n",
    "    # Step 3: Load\n",
    "    load(clean_df, \"D:\\python files\\pandas\\clean_sales_extended.json\")\n",
    "\n",
    "    return clean_df\n",
    "\n",
    "# Run the complete pipeline\n",
    "final_df = run_etl()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef5b0d7-a4de-466c-a765-99b5695cf910",
   "metadata": {},
   "source": [
    "Task6:Complete a short hands-on test and an assignment to extend the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0002577-3c09-4686-bf71-7ca93521ffb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name\n",
       "Stapler    1041\n",
       "Name: quantity, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Which product was sold the most (total quantity)?\n",
    "df_sales.groupby(\"product_name\")[\"quantity\"].sum().sort_values(ascending=False).head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d9da880-b559-4c06-b6db-ec2d34b8eb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many transactions used a promo code?\n",
    "df_sales[df_sales[\"promo_code\"] != \"NONE\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "303d6a1c-f738-4dc1-ac2e-4b45cdc1c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DataFrame with new Customer Engagement Score column:\n",
      "   quantity  total promo_code  engagement_score\n",
      "0         2   7.00       NONE              4.30\n",
      "1         5   4.00     DISC10              6.00\n",
      "2         1   3.50       NONE              2.15\n",
      "3         1   5.25       NONE              3.02\n",
      "4         3   3.60     DISC10              5.00\n",
      "\n",
      " Saved: sample_extended_with_CES.csv\n"
     ]
    }
   ],
   "source": [
    "# Create the promo flag\n",
    "df_sales[\"promo_used_flag\"] = np.where(df_sales[\"promo_code\"] != \"NONE\", 1, 0)\n",
    "\n",
    "# Create the unique Customer Engagement Score(created by me-random creation)\n",
    "df_sales[\"engagement_score\"] = (\n",
    "    df_sales[\"quantity\"] * 0.4 +\n",
    "    df_sales[\"total\"] * 0.5 +\n",
    "    df_sales[\"promo_used_flag\"] * 2\n",
    ").round(2)\n",
    "\n",
    "print(\" DataFrame with new Customer Engagement Score column:\")\n",
    "print(df_sales[[\"quantity\", \"total\", \"promo_code\", \"engagement_score\"]].head())\n",
    "\n",
    "# Save the updated file\n",
    "df_sales.to_csv(r\"D:\\python files\\pandas\\sample_extended_with_CES.csv\", index=False)\n",
    "\n",
    "print(\"\\n Saved: sample_extended_with_CES.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea9a879-8b97-4c0c-919c-4016ef389079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
